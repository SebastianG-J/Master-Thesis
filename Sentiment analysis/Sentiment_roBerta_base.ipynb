{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+XvKN9pU7sx5swmDsTvQT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 1. Install dependencies"],"metadata":{"id":"Um4hRA8eVjna"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3VZ6w1EVSus"},"outputs":[],"source":["pip install transformers torch pandas openpyxl"]},{"cell_type":"markdown","source":["## 2. Load the Model and Tokenizer"],"metadata":{"id":"2s6lUNENVsB5"}},{"cell_type":"code","source":["import pandas as pd\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","import torch\n","\n","# Check if GPU is available and set device\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Load model and tokenizer\n","model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","\n","# Move model to GPU if available\n","model.to(device)\n","\n","# Define labels for interpretation\n","labels = [\"negative\", \"neutral\", \"positive\"]\n"],"metadata":{"id":"MF3htnXxVbob","executionInfo":{"status":"ok","timestamp":1743158384132,"user_tz":-60,"elapsed":6,"user":{"displayName":"Sebastian Grunnet-Jensen","userId":"16913492812005265890"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## 3. Load the Excel File"],"metadata":{"id":"wmsv_uWIVwvL"}},{"cell_type":"code","source":["# Load the Excel file\n","file_path = \"your_file.xlsx\"  # Change to your file path\n","df = pd.read_excel(file_path)\n","\n","# Assuming X_Posts are in a column named 'X_Post'\n","X_Post = df[\"X_Post\"].astype(str).tolist()\n"],"metadata":{"id":"C2icld7eV0XJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Process the Tweets and Get Sentiment\n"],"metadata":{"id":"QFFExpssV9ND"}},{"cell_type":"code","source":["def get_sentiment_batch(texts):\n","    inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n","    return [labels[p] for p in predictions]\n","\n","# Process in batches (example: batch size 32)\n","batch_size = 32\n","df[\"sentiment\"] = [\n","    sentiment for i in range(0, len(df), batch_size)\n","    for sentiment in get_sentiment_batch(df[\"X_Post\"][i:i+batch_size].tolist())\n","]\n","\n","# Apply sentiment analysis to all X_Posts\n","df[\"sentiment\"] = df[\"X_Post\"].apply(get_sentiment)\n"],"metadata":{"id":"BU5CtNBvWBBv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Save the Results\n"],"metadata":{"id":"du0XngWoWCg-"}},{"cell_type":"code","source":["# Save the DataFrame with sentiment labels back to an Excel file\n","output_path = \"X_Posts_with_sentiment.xlsx\"\n","df.to_excel(output_path, index=False)\n","\n","print(\"Sentiment analysis completed and saved to:\", output_path)"],"metadata":{"id":"7tSm8LEzV_82"},"execution_count":null,"outputs":[]}]}